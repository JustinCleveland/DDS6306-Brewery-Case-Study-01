---
title: "Brewery  Case Study"
author: "Thomas Pengilly"
date: "2/22/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

###############################################################################################################################################

# Doing Data Science: Case Study 1: Brewery Case Study
# The code in this file will conduct EDA on the Beers.csv and Breweries.csv files provided in order to answer the questions posed in the Case Study 01 document.
# Each chunk of code should be clearly and fully explained in a sentence or two before the code chunk.

###############################################################################################################################################





###############################################################################################################################################
################################################################ Introduction #################################################################
###############################################################################################################################################

# Our goal is to provide any interesting or useful insights gained from the analysis of beer and brewery data provided by Budweiser.  In exploring the beer data we will analyze variables including ABV (alcohol content by volume), IBU (International Bitterness Units), the brewer, brewery location, beer style, and the volume in ounces of the beer of interest in order to find interesting correlations.

###############################################################################################################################################
###############################################################################################################################################
###############################################################################################################################################





###############################################################################################################################################
######################################################### Analysis Questions ##################################################################
###############################################################################################################################################



###############################################################################################################################################
############################################################ Question 1 #######################################################################
###############################################################################################################################################

### 1. How many breweries are present in each state?

# This will load the necessary libraries, read in the brewery data, and display the first 10 entries.
```{r}
# Load required Libraries
library(ggplot2)
library(plyr)
library(tidyverse)
library(GGally)
library(caret)
library(class)
library(e1071)

# Read in brewery data
brewery_data = read.csv('C:/Users/Tpeng/OneDrive/Documents/SMU/Doing Data Science/Unit 8 Project/Breweries.csv', header = TRUE, na.strings =c('', 'NA'))
brewery_data
```

# This summarizes the number of breweries in each state and plots a barchart of the results.
```{r}
# Create an object that counts breweries by state, to be used for reordering data
state_counts = data.frame(table(brewery_data$State))
colnames(state_counts)  = c("State", "Freq")
state_counts = state_counts[order(state_counts$Freq),]

# Plot the ordered results
state_counts %>% ggplot(aes(x = reorder(State, Freq), y = Freq, fill = State)) +
  geom_bar(stat = 'identity') + 
  coord_flip() + 
  ggtitle('Number of Breweries by State') + 
  ylab('Count') + 
  xlab('State')
```

# This creates a heatmap for the number of breweries in each state.  The number of breweries is plotted in the center of each state.
```{r}
library(ggplot2)
library(maps)
library(dplyr)
library(mapproj)
new_brewery_data = brewery_data
lookup = data.frame(abb = state.abb, State = state.name)    #makes a data frame with State name and abbreviation. (from one of libraries)
colnames(new_brewery_data)[4] = "abb"    # Change Column Name so we have matching keys b/t datasets
brewery_data2 = merge(new_brewery_data,lookup, by ="abb", all.x = TRUE, no.dups = F)    # make one dataset with state names and abb
brewery_data2 = brewery_data2[!brewery_data2$abb == ' DC',]
levels(brewery_data2$State) = levels(lookup$State)
levels(lookup$abb) = levels(brewery_data2$abb)

for (row in 1:nrow(brewery_data2)){
  abb = as.character(brewery_data2$abb[row])
  abb = trimws(abb)
  brewery_data2$State[row] = state.name[which(state.abb == abb)]
}

NumBreweryMapData = count(brewery_data2, State)    #count up the occurance of each state. 
colnames(NumBreweryMapData)[2] = "Breweries"    #change "n" to "Acuspikes"
NumBreweryMapData$region <- tolower(NumBreweryMapData$State)    # renamed state to region to merge with dataframe of map data later
NumBreweryMapData2 = NumBreweryMapData[-1]
states <- map_data("state")    # This creates the visual map of states boundaries, etc

map.df <- merge(states,NumBreweryMapData2, by="region", all.x=T)
map.df <- map.df[order(map.df$order),]

tibble = map.df %>% group_by(region) %>% summarise(midlat = mean(c(max(lat), min(lat))), midlong = mean(c(max(long), min(long))))
for (row in 1:nrow(map.df)){
  region = map.df$region[row]
  midlat = tibble[tibble$region == region,]$midlat
  midlong = tibble[tibble$region == region,]$midlong
  map.df$midlat[row] = midlat
  map.df$midlong[row] = midlong
}

ggplot(map.df, aes(x=long,y=lat,group=group)) + 
  geom_polygon(aes(fill=Breweries)) +
  geom_path() + 
  scale_fill_gradientn(colours=rev(heat.colors(10)),na.value="grey90") +
  ggtitle("Number of Breweries in Each State") +  
  coord_map() + 
  geom_text(label = map.df$Breweries, x = map.df$midlong, y = map.df$midlat) +
  theme(plot.title = element_text(hjust = 0.5))

```


###############################################################################################################################################
############################################################ Question 2 #######################################################################
###############################################################################################################################################

### 2. Merge beer data with the breweries data. Print the first and last 6 observations to check the merged file.

# The following code reads in the beer dataset and merges it with the brewery data such that each brewery will now contain the all information regarding its beers present in the beer dataset. It will then print the  first and last 6 observations to verify that it worked correctly.
```{r}
# Read in Beer data and merge with brewery data
beer_data = read.csv('C:/Users/Tpeng/OneDrive/Documents/SMU/Doing Data Science/Unit 8 Project/Beers.csv', header = TRUE, na.strings = c('', 'NA'))

dataset = merge(brewery_data, beer_data, by.x = 'Brew_ID', by.y = 'Brewery_id', all = TRUE)

# Print first and last 6 observations
dataset[1:6,]
tail(dataset, 6)
```

###############################################################################################################################################
############################################################ Question 3########################################################################
###############################################################################################################################################

### 3. Address the missing values in each column (ABV and IBU).

# This code removes any beers with a missing style (there are 5).  It then calculates the average ABV and IBU for each style of beer, and assigns this value to any beer of that style with missing values. 
```{r}
# Remove beers missing values for Style
dataset = dataset[!is.na(dataset$Style),]

# Calculate average values for ABV and IBU and store in a dataframe
avg_abv = dataset %>% group_by(Style) %>% summarize(meanABV = mean(ABV, na.rm = TRUE))
avg_abv = as.data.frame(avg_abv)

grand_mean_abv = dataset %>% summarize(grand_mean_abv = mean(ABV, na.rm = TRUE))
grand_mean_ibu = dataset %>% summarize(grand_mean_ibu = mean(IBU, na.rm = TRUE))

avg_ibu = dataset %>% group_by(Style) %>% summarize(meanibu  = mean(IBU, na.rm = TRUE))
avg_ibu = as.data.frame(avg_ibu)

# Replace missing average IBU's with grand mean IBU in IBU dataframe
avg_ibu$meanibu = ifelse(is.na(avg_ibu$meanibu), grand_mean_ibu, avg_ibu$meanibu)

# Replace missing ABV's and IBU's in full dataset with averages by Style
for (row in 1:nrow(dataset)){
  
  if(is.na(dataset[row, 'ABV'])){
    dataset[row, 'ABV'] = avg_abv[avg_abv$Style == dataset$Style[row],]$meanABV[1]
  }
  if(is.na(dataset[row, 'IBU'])){
    dataset[row, 'IBU'] = avg_ibu[avg_ibu$Style == dataset$Style[row],]$meanibu[1]
  }
}
```



###############################################################################################################################################
############################################################ Question 4 #######################################################################
###############################################################################################################################################

### 4. Compute the median alcohol content and IBU for each state.  Plot a bar chart to compare.

# This code computes the median ABV and IBU by state, and then prints the state with the highest median ABV and IBU. It also creates a median dataframe, that is used for a heatmap. The state with the highest median ABV is Kentucky, that with the highest median IBU is Delaware.
```{r}
# Find and display median values
median_abv = dataset %>% group_by(State) %>% summarize(medianABV = median(ABV))
median_abv = as.data.frame(median_abv)

median_ibu = dataset %>% group_by(State) %>% summarize(medianIBU = median(IBU))
median_ibu = as.data.frame(median_ibu)

# Determine which observation has maximum values and output the state
median_abv$State[which.max(median_abv$medianABV)] # Kentucky
median_ibu$State[which.max(median_ibu$medianIBU)] # Delaware
median_data = merge(median_abv, median_ibu, by = 'State')
```

# This plots the median ABV and IBU by state on a heatmap for an easy-to-read summary of the data.
```{r}
library(ggplot2)
library(maps)
library(dplyr)
library(mapproj)

lookup = data.frame(abb = state.abb, State = state.name) #makes a data frame with State name and abbreviation. (from one of libraries)
colnames(median_data)[1] = "abb" # Change Column Name so we have matching keys b/t datasets
median_data2 = merge(median_data,lookup, by ="abb", all.x = TRUE, no.dups = F) # make one dataset with state names and abb
median_data2 = median_data2[!median_data2$abb == ' DC',]
levels(median_data2$State) = levels(lookup$State)
levels(lookup$abb) = levels(median_data2$abb)

for (row in 1:nrow(median_data2)){
  abb = as.character(median_data2$abb[row])
  abb = trimws(abb)
  median_data2$State[row] = state.name[which(state.abb == abb)]
}

median_data2$region <- tolower(NumBreweryMapData$State) # renamed state to region to merge with dataframe of map data later

states <- map_data("state") # This creates the visual map of states boundaries, etc
# Heat maps require all data to be in single data frame, from states boundaries ^ to counts (sales) for states
map.df <- merge(states,median_data2, by="region", all.x=T)
map.df <- map.df[order(map.df$order),]

tibble = map.df %>% group_by(region) %>% summarise(midlat = mean(c(max(lat), min(lat))), midlong = mean(c(max(long), min(long))))
for (row in 1:nrow(map.df)){
  region = map.df$region[row]
  midlat = tibble[tibble$region == region,]$midlat
  midlong = tibble[tibble$region == region,]$midlong
  map.df$midlat[row] = midlat
  map.df$midlong[row] = midlong
}

#  Convert ABV to percent
map.df$Percent = map.df$medianABV * 100

ggplot(map.df, aes(x=long,y=lat,group=group)) + 
  geom_polygon(aes(fill=Percent)) +
  geom_path() + 
  scale_fill_gradientn(colours=rev(rainbow(10)),na.value="grey90") +
  ggtitle("Median ABV in Each State") +  
  coord_map() + 
  theme(plot.title = element_text(hjust = 0.5)) + 
  labs(fill = 'ABV (%)')

ggplot(map.df, aes(x=long,y=lat,group=group)) + 
  geom_polygon(aes(fill=medianIBU)) +
  geom_path() + 
  scale_fill_gradientn(colours=rev(rainbow(10)),na.value="grey90") +
  ggtitle("Median IBU in Each State") +  
  coord_map() + 
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(fill = 'IBU Rating')
```

# This creates a bar chart for median ABV and IBU for each state.
```{r}
median_abv %>% ggplot(aes(x= reorder(State, median_abv$medianABV, fun = median), y = medianABV, fill = State)) + 
  geom_bar(stat = 'identity') + 
  coord_flip() + 
  ggtitle('Median Beer Alcohol Content By State') + 
  ylab('Alcohol Content') + 
  xlab('State')

median_ibu %>% ggplot(aes(x= reorder(State, median_ibu$medianIBU, fun = median), y = medianIBU, fill = State)) + 
  geom_bar(stat = 'identity') + 
  coord_flip() + 
  ggtitle('Median Beer IBU  By State') + 
  ylab('IBU Rating') + 
  xlab('State')
```





###############################################################################################################################################
############################################################ Question 5 #######################################################################
###############################################################################################################################################

### 5. Which state has the most alcoholic beer, and which has the most bitter beer?

# The following code determines which states have the highest beer ABV and IBU, and prints them out. The state with the highest ABV beer is Colorado, and the state with the highest IBU is Oregon.
```{r}
state_maxABV = dataset$State[which.max(dataset$ABV)]
state_maxIBU = dataset$State[which.max(dataset$IBU)]
state_maxABV # Colorado
state_maxIBU # Oregon
```


# This code creates a heatmap for the max ABV and IBU for beer in each state.
```{r}
# Find and display max values
max_abv = dataset %>% group_by(State) %>% summarize(maxABV = max(ABV))
max_abv = as.data.frame(max_abv)
max_ibu = dataset %>% group_by(State) %>% summarize(maxIBU = max(IBU))
max_ibu = as.data.frame(max_ibu)
max_data = merge(max_abv, max_ibu, by = 'State')

lookup = data.frame(abb = state.abb, State = state.name) #makes a data frame with State name and abbreviation. (from one of libraries)
colnames(max_data)[1] = "abb" # Change Column Name so we have matching keys b/t datasets
max_data2 = merge(max_data,lookup, by ="abb", all.x = TRUE, no.dups = F) # make one dataset with state names and abb
max_data2 = max_data2[!max_data2$abb == ' DC',]
levels(max_data2$State) = levels(lookup$State)
levels(lookup$abb) = levels(max_data2$abb)

for (row in 1:nrow(max_data2)){
  abb = as.character(max_data2$abb[row])
  abb = trimws(abb)
  max_data2$State[row] = state.name[which(state.abb == abb)]
}

max_data2$region <- tolower(NumBreweryMapData$State) # renamed state to region to merge with dataframe of map data later

states <- map_data("state") # This creates the visual map of states boundaries, etc

map.df <- merge(states,max_data2, by="region", all.x=T)
map.df <- map.df[order(map.df$order),]

tibble = map.df %>% group_by(region) %>% summarise(midlat = mean(c(max(lat), min(lat))), midlong = mean(c(max(long), min(long))))
for (row in 1:nrow(map.df)){
  region = map.df$region[row]
  midlat = tibble[tibble$region == region,]$midlat
  midlong = tibble[tibble$region == region,]$midlong
  map.df$midlat[row] = midlat
  map.df$midlong[row] = midlong
}

map.df$Percent = map.df$maxABV * 100

ggplot(map.df, aes(x=long,y=lat,group=group)) + 
  geom_polygon(aes(fill=maxABV)) +
  geom_path() + 
  scale_fill_gradientn(colours=rev(rainbow(10)),na.value="grey90") +
  ggtitle("Max ABV in Each State") +  
  coord_map() + 
  theme(plot.title = element_text(hjust = 0.5)) + 
  labs(fill = 'ABV (%)')

ggplot(map.df, aes(x=long,y=lat,group=group)) + 
  geom_polygon(aes(fill=maxIBU)) +
  geom_path() + 
  scale_fill_gradientn(colours=rev(rainbow(10)),na.value="grey90") +
  ggtitle("Max IBU in Each State") +  
  coord_map() + 
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(fill = 'IBU Rating')
```





###############################################################################################################################################
############################################################ Question 6 #######################################################################
###############################################################################################################################################

###6. Comment on the summary statistics and distribution of ABV

# This will summarize the statistics of ABV by beer
```{r}
# Get summary statistics
summary(dataset$ABV)
mean(dataset$ABV)
sd(dataset$ABV)
```

# This plots overall distribution of ABV in a histogram.
```{r}
# Plot Overall ABV distribution colored by state.
dataset %>% ggplot(aes(fill = State)) +geom_histogram(aes(x = dataset$ABV), binwidth = 0.005)
```

# This code selects only popular beer styles (n > 75), then plots histograms of the ABV and IBU's by style.
```{r}
popular_beers_tibble = count(dataset, Style)
popular_beers_tibble = popular_beers_tibble %>% filter(popular_beers_tibble$n > 75)
popular_beers = merge(dataset, popular_beers_tibble, by = 'Style', all.x = FALSE, all.y = TRUE)

popular_beers %>% ggplot() + geom_histogram(aes(x = popular_beers$ABV, fill = Style)) + facet_wrap(popular_beers$Style) + theme(legend.position = 'none')
popular_beers %>% ggplot() + geom_histogram(aes(x = popular_beers$IBU, fill = Style)) + facet_wrap(popular_beers$Style) + theme(legend.position = 'none')
```





###############################################################################################################################################
############################################################ Question 7 #######################################################################
###############################################################################################################################################

### 7. Is there an apparent relationship between beer bitterness and alcohol content?

# This code creates a scatterplot of ABV vs IBU for all beers. 
```{r}
dataset %>% ggplot(aes(x = ABV, y = IBU)) + 
  geom_point(position = 'jitter') + 
  stat_smooth(method = 'lm', se = FALSE) +
  ggtitle("Relationship Between IBU and ABV") + theme(legend.position = 'none', plot.title = element_text(hjust = 0.5))
```

# This code explores the ABV-IBU relationship of specific beer styles (IPA's and Ales) to get more insights into the relationship, which appears more complicated than initially thought. The two styles analyzed display different relationships.
```{r}
# Create datasets for IPA's and Ales, remove any IPA's that are in ale dataset. Condense beers into 2 styles, IPA and Ale, then combine into a single dataframe
ipa_dataset = dataset %>% filter(grepl('.*IPA.*', dataset$Style))
ale_dataset = dataset %>% filter(grepl('.*Ale.*', dataset$Style))
ale_dataset = ale_dataset %>% filter(!grepl('.*IPA.*', ale_dataset$Style))
ipa_dataset$Style = c('IPA')
ale_dataset$Style = c('Ale')
ipa_ale_dataset = rbind(ipa_dataset, ale_dataset)

ipa_ale_dataset %>% ggplot(aes(x = ABV, y = IBU, color = Style))  + geom_point(position = 'jitter') + ggtitle('Alcohol Content vs Bitterness') + scale_color_manual(values = c('red', 'blue')) + theme(plot.title = element_text(hjust = 0.5))

```





###############################################################################################################################################
############################################################ Question 8 #######################################################################
###############################################################################################################################################

#### 8. Investigate the difference with respect to IBU and ABV between IPAs and all other Ales (excluding IPA's). Use KNN. May supplement with other approaches.

# This code creates a subset of the data containing only IPA's and all other Ales combined in a common 'Ale' group (duplicated from above), then splits this subset into a training set and a test set.
```{r}
# Need to filter into two groups: IPA and Ale
ipa_dataset = dataset %>% filter(grepl('.*IPA.*', dataset$Style))
ale_dataset = dataset %>% filter(grepl('.*Ale.*', dataset$Style))
ale_dataset = ale_dataset %>% filter(!grepl('.*IPA.*', ale_dataset$Style))
ipa_dataset$Style = c('IPA')
ale_dataset$Style = c('Ale')
ipa_ale_dataset = rbind(ipa_dataset, ale_dataset)

splitpercent = .70
trainIndices = sample(1:dim(ipa_ale_dataset)[1], round(splitpercent * dim(ipa_ale_dataset)[1]))
train = ipa_ale_dataset[trainIndices,]
test = ipa_ale_dataset[-trainIndices,]
```

# This code iterates through multiple dataset samples and k-values to estimate the optimum K-value (k = 5). The results of the iteration are plotted below.
```{r}
iterations = 100
numks = 30
masteracc = matrix(nrow = iterations, ncol = numks)
splitpercent = .70
for(j in 1:iterations)
{ 
  accs = data.frame(accuracy = numeric(numks), k = numeric(numks))
  trainIndices = sample(1:dim(ipa_ale_dataset)[1], round(splitpercent * dim(ipa_ale_dataset)[1]))
  train = ipa_ale_dataset[trainIndices,]
  test = ipa_ale_dataset[-trainIndices,]
    
  for (i in 1:numks)
    {
    classifications = knn(train[,c(7,8)],test[,c(7,8)],train$Style, prob = TRUE, k = i)
    tab = table(classifications,test$Style)
    CM = confusionMatrix(tab)
    masteracc[j,i] = CM$overall[1]
  }
}
MeanAcc = colMeans(masteracc)
plot(seq(1,numks,1), MeanAcc, type = 'l')
```

# This code runs the classifier model and outputs the performance metrics of the model. The model selected was the K-NN model with k = 5.  The model selects the 5 closest beers, in terms of ABV and IBU, to each beer in the test set, and assigns the majority style to the beer in question.
```{r}
classifications = knn(train[,c(7,8)],test[,c(7,8)],train$Style, prob = TRUE, k = 5)
CM = confusionMatrix(table(test$Style,classifications))
CM
```

### We decided to try a different model, leave-one out cross validation, to get better results.  

# This code runs a Leave one out cross validation model over multiple data samples and k-values to determine the optimum K (k = 5 is optimum).  This model is similar to the previous one, but utilizes the entire dataset to train instead of 70% of the data. 
```{r}
accs = data.frame(accuracy = numeric(90), k = numeric(90))

for (i in 1:90)
{
  classifications = knn.cv(ipa_ale_dataset[,c(7,8)], ipa_ale_dataset$Style, prob = TRUE, k = i)
  CM = confusionMatrix(table(classifications, ipa_ale_dataset$Style))
  accs$accuracy[i] = CM$overal[1]
  accs$k[i] = i
}

plot(accs$k, accs$accuracy, type = 'l', xlab = 'k')
```

# Now we run our model to determine the performance metrics for the new model.  This model achieves slightly better accuracy than the previous model, since it uses more data to train the model.
```{r}
classifications = knn.cv(ipa_ale_dataset[,c(7,8)], ipa_ale_dataset$Style, prob = TRUE, k = 5)
CM = confusionMatrix(table(classifications, ipa_ale_dataset$Style))
CM
```

# This creates a dataframe that stores the performance metrics of our KNN model, to be used to analyze the results.  It includes the model classifications, probabilities, the beer's true style, ABV, and IBU.
```{r}
class_df = data.frame('classification' = classifications)
probability = attributes(classifications)[3][1]
probability = unlist(probability[1])
for (var in probability){
  attr(probability, 'names') <- NULL
}
class_df = cbind(class_df, probability)
class_df = cbind(ipa_ale_dataset$Style, class_df, ipa_ale_dataset$ABV, ipa_ale_dataset$IBU)
names(class_df) = c('Truth', 'Classification', 'Probability', 'ABV', 'IBU')
class_df$Correct = ifelse(class_df$Truth == class_df$Classification, 'Correct Prediction', 'Incorrect Prediction')
class_df$Correct = ordered(class_df$Correct, levels = c("Incorrect Prediction", "Correct Prediction"))
class_df$Numeric = ifelse(class_df$Truth == 'IPA', 1, 0)
class_df$AleProb = ifelse(class_df$Classification == 'Ale', class_df$Probability, 1 - class_df$Probability)
```

# Create a 3D plot showing the models performance as color with respect to the true beer style on the z-axis.  
#This plot shows that the model makes a fair amount of errors across all ABV values, indicating low correlation between style and ABV.  It also shows a significant boundary in the IBU range of ~ 40-60, above or below which it is highly accurate in predicting the beer style, indicating a possible correlation between IBU and beer style.  This is explored further.
```{r}
library(plotly)
model_plot <- plot_ly(class_df, x = ~ABV, y = ~IBU, z = ~Truth, color = ~Correct, colors = 'Set1')
model_plot <- model_plot %>% add_markers()
model_plot <- model_plot %>% layout(title = 'Distribution of ABV and IBU By Style', scene = list(xaxis = list(title = 'ABV'),
                                  yaxis = list(title = 'IBU'),
                                  zaxis = list(title = 'True Style')))
model_plot
```

# Create a 3D plot Comparing ABV and IBU to the probability of being an Ale colored by the models prediction accuracy. This confirms that the probability of being an Ale is not affected by ABV, but shows a significant visual correlation between IBU and probability of being an Ale. The model errors are fairly evenly distributed across IBU and ABV indicating a complex relationship that is not fully captured by these two variables.
```{r}
library(plotly)
class_df$`Ale Probability`= class_df$AleProb * 100

model_plot <- plot_ly(class_df, x = ~ABV, y = ~IBU, z = ~`Ale Probability`, color = ~Correct, colors = 'Set1')
model_plot <- model_plot %>% add_markers()
model_plot <- model_plot %>% layout(title = 'Distribution of ABV and IBU By Style', scene = list(xaxis = list(title = 'ABV'),
                                  yaxis = list(title = 'IBU'),
                                  zaxis = list(title = 'Probability of Being an Ale (%)')))
model_plot
```

# Create a 2D plot of ABV vs IBU colored by model correctness 
```{r}
class_df %>% ggplot(aes(x = IBU, y = ABV, color = Correct)) + geom_point(position = 'jitter') + ggtitle('KNN Model Performance') +
  scale_color_manual(values = c('red', 'blue')) + theme(plot.title = element_text(hjust = 0.5))
```


# Create scatterplots of probability of being an ale vs ABV and probability of being an ale vs IBU colored by model correctness
```{r}
class_df$`Ale Probability` = class_df$AleProb * 100
class_df %>% ggplot(aes(x = ABV, y = `Ale Probability`, color = Truth))  + geom_point(position = 'jitter') + ggtitle('Predicted Style Probabilities (ABV)') + scale_color_manual(values = c('red', 'blue')) + ylab('Probability of Being an Ale (%)') + theme(plot.title = element_text(hjust = 0.5))
class_df %>% ggplot(aes(x = IBU, y = `Ale Probability`, color = Truth))  + geom_point(position = 'jitter') + ggtitle('Predicted Style Probabilities (IBU)') + scale_color_manual(values = c('red', 'blue')) + ylab('Probability of Being an Ale (%)') + theme(plot.title = element_text(hjust = 0.5))

```





### Create a logistic regression model for classification in order to determine statistical significance of relationships. ( Include K-fold validation later)

# Create training and test sets
```{r}
library(ISLR)
library(gridExtra)

ipa_ale_dataset$Style = as.factor(ipa_ale_dataset$Style)
splitpercent = .70
trainIndices = sample(1:dim(ipa_ale_dataset)[1], round(splitpercent * dim(ipa_ale_dataset)[1]))
ipa_ale_train = ipa_ale_dataset[trainIndices,]
ipa_ale_test = ipa_ale_dataset[-trainIndices,]

```

# Train and test logistic regression model and output its performance metrics. This model is capable of ascertaining the statistical significance of the relationships.  It confirms our intuitions that IBU is significantly correlated to style, while ABV is not.
```{r}
logistic_regression_model = glm(Style ~ ABV + IBU,  family = binomial(link = 'logit'), data = ipa_ale_train)
summary(logistic_regression_model)

fitted.results = predict(logistic_regression_model, newdata = subset(ipa_ale_test, select = c(7, 8)), type = 'response')
log.probs = as.data.frame(fitted.results)$fitted.results
ipa_ale_test$Prob_IPA = log.probs
fitted.results = ifelse(fitted.results > 0.5, 'IPA', 'Ale')

misclass_error = mean(fitted.results != ipa_ale_test$Style)
print(paste('Accuracy is ', 1 - misclass_error))
```




###################### NEEDS WORK ############################## IF USED #######################
# Train and test cross validated logistic regression model and output its performance metrics. This model is capable of ascertaining the statistical significance of the relationships.  It confirms our intuitions that IBU is significantly correlated to style, while ABV is not.
```{r}
library(boot)
cv_logistic_regression_model = cv.glm(data = ipa_ale_dataset, glmfit = logistic_regression_model, K = 10)
summary(cv_logistic_regression_model)

cv_logistic_regression_model$delta
```

########################################################






#################################################### KEEP THIS ######################################################################

# Plot the performance of the logistic regression model
```{r}
# Create dataframe of test set and model results
ipa_ale_test$Predicted_Style = fitted.results
ipa_ale_test$Correct = ifelse(ipa_ale_test$Style == ipa_ale_test$Predicted_Style, 'Correct Prediction', 'Incorrect Prediction')

ipa_ale_test %>% ggplot(aes(x = IBU, y = ABV, color = Correct)) + geom_point(position = 'jitter') + ggtitle('Logistic Model Performance') + scale_color_manual(values = c('blue', 'red'))
```

# Plot 3D results of model performance with true style as the z axis.  This plot shows a definitive boundary of IBU = ~55 above which is IPA, below which is Ale.  No such boundary exists for ABV.
```{r}
library(plotly)
logmodel_plot <- plot_ly(ipa_ale_test, x = ~IBU, y = ~ABV, z = ~Style, color = ~Correct, colors = c('blue', 'red'))
logmodel_plot <- logmodel_plot %>% add_markers()
logmodel_plot <- logmodel_plot %>% layout(title = 'Logistic Regression Model Performance By Style', scene = list(xaxis = list(title = 'IBU'),
                                  yaxis = list(title = 'ABV'),
                                  zaxis = list(title = 'True Style')))
logmodel_plot
```

# Plot 3D results of model performance with IPA Probability as the z axis.  THis further confirms our intuition.
```{r}
library(plotly)
logmodel_plot <- plot_ly(ipa_ale_test, x = ~IBU, y = ~ABV, z = ~Prob_IPA, color = ~Correct, colors = c('blue', 'red'))
logmodel_plot <- logmodel_plot %>% add_markers()
logmodel_plot <- logmodel_plot %>% layout(title = 'Logistic Regression Model Performance Probability', scene = list(xaxis = list(title = 'IBU'),
                                  yaxis = list(title = 'ABV'),
                                  zaxis = list(title = 'Probability of Being an IPA')))
logmodel_plot
```




####################################################################################################################################################
############################################################# Question 9 ###########################################################################
####################################################################################################################################################

#### 9. Find one other useful piece of information in the data. Convince them why it's important and back it up.
# We will determine which beer styles are popular across all 50 states.

# This code condenses beer styles into a few common types, such as: IPA, Ale, Pale Ale, Lager, Stout, Pilsner, Witbier, and Porter
```{r}
# Need to filter into two groups: IPA and Ale
ipa_dataset = dataset %>% filter(grepl('.*IPA.*', dataset$Style))

ale_dataset = dataset %>% filter(grepl('.* Ale.*', dataset$Style))
ale_dataset = ale_dataset %>% filter(!grepl('.*IPA.*', ale_dataset$Style))
ale_dataset = ale_dataset %>% filter(!grepl('.* Pale.*', ale_dataset$Style))

pale_ale_dataset = dataset %>% filter(grepl('.* Pale.*', dataset$Style))
pale_ale_dataset = pale_ale_dataset %>% filter(!grepl('.*IPA.*', pale_ale_dataset$Style))

lager_dataset = dataset %>% filter(grepl('.*Lager.*', dataset$Style))
stout_dataset = dataset %>% filter(grepl('.*Stout.*', dataset$Style))
pilsner_dataset = dataset %>% filter(grepl('.*Pilsner.*', dataset$Style))
witbier_data = dataset %>% filter(grepl('.*Witbier.*', dataset$Style))
porter_data = dataset %>% filter(grepl('.*Porter.*', dataset$Style))

ipa_dataset$Style = c('IPA')
ale_dataset$Style = c('Ale')
pale_ale_dataset$Style = c('Pale Ale')
lager_dataset$Style = c('Lager')
stout_dataset$Style = c('Stout')
pilsner_dataset$Style = c('Pilsner')
witbier_data$Style = c('Witbier')
porter_data$Style = c('Porter')

styled_dataset = rbind(ipa_dataset, ale_dataset, pale_ale_dataset, lager_dataset, stout_dataset, pilsner_dataset, witbier_data, porter_data)
styled_dataset = styled_dataset[order(styled_dataset$State),]
styled_dataset$Style = as.factor(styled_dataset$Style)
styled_dataset$State = as.factor(styled_dataset$State)
```

# Find favorite beer in each state, and create a table containing the statistics.
```{r}
beer_counts = styled_dataset %>% group_by(State) %>% count(Style)
beer_counts = beer_counts[with(beer_counts, order(beer_counts$State, -beer_counts$n)),]

beer_count_spread = spread(beer_counts, Style, n)
beer_count_spread[is.na(beer_count_spread)] = 0
beer_counts = subset(beer_counts, beer_counts$State != ' DC')

row = 1
for (row in 1:nrow(beer_count_spread)){
  beer_count_spread$Total[row] = sum(beer_count_spread[row ,2:9])
  row = row + 1
}

favorites = data.frame(matrix('', ncol = 2, nrow = 50))
names(favorites) = c('State', 'Style')
levels(favorites$State) = levels(styled_dataset$State)
levels(favorites$Style) = levels(styled_dataset$Style)
favorites$State = max_data2$abb
favorites$Style = c(NA)
favorites$Style = as.factor(favorites$Style)
faclevels = addNA(levels(beer_counts$Style))
levels(favorites$Style) = faclevels

row  =1
faverow = 1

for (row in 1:nrow(beer_counts)) {
  state = beer_counts$State[row]
  style = beer_counts$Style[row]
  
  if(is.na(favorites[favorites$State == state,]$Style)) {
    favorites$Style[faverow] = style
    faverow = faverow + 1
  }
  row = row + 1
}

levels(favorites$Style) = levels(styled_dataset$Style)
```

### Create Heatmap of favorite beers by State
```{r}
library(ggplot2)
library(maps)
library(dplyr)
library(mapproj)

lookup = data.frame(abb = state.abb, State = state.name) #makes a data frame with State name and abbreviation. (from one of libraries)
colnames(favorites)[1] = "abb" # Change Column Name so we have matching keys b/t datasets
favorites2 = merge(favorites,lookup, by ="abb", all.x = TRUE, no.dups = F) # make one dataset with state names and abb
levels(favorites2$State) = levels(lookup$State)
levels(lookup$abb) = levels(favorites2$abb)

#### Trying to fit this in
#favorites2 = favorites2[!brewery_data2$abb == ' DC',]
#levels(favorites2$State) = levels(lookup$State)
#levels(lookup$abb) = levels(favorites2$abb)

#####

for (row in 1:nrow(favorites2)){
  abb = as.character(favorites2$abb[row])
  abb = trimws(abb)
  favorites2$State[row] = state.name[which(state.abb == abb)]
}

favorites2$region <- tolower(favorites2$State) # renamed state to region to merge with dataframe of map data later

states <- map_data("state") # This creates the visual map of states boundaries, etc
# Heat maps require all data to be in single data frame, from states boundaries ^ to counts (sales) for states
map.df <- merge(states,favorites2, by="region", all.x=T)
map.df <- map.df[order(map.df$order),]


ggplot(map.df, aes(x=long,y=lat,group=group)) + 
  geom_polygon(aes(fill=Style)) +
  geom_path() + 
  ggtitle('Most Brewed Beer in Each State') +  
  coord_map() + theme(plot.title = element_text(hjust = 0.5))

```





# Check out wheat beers
```{r}
wheat_dataset = dataset %>% filter(grepl('.*Wheat.*', dataset$Style) | grepl('.*Hefeweizen.*', dataset$Style) | grepl('.*Witbier.*', dataset$Style))
# Reset ale dataset
ale_dataset = dataset %>% filter(grepl('.* Ale.*', dataset$Style))
ale_dataset = ale_dataset %>% filter(!grepl('.*IPA.*', ale_dataset$Style))
ale_dataset = ale_dataset %>% filter(!grepl('.* Pale.*', ale_dataset$Style))

ale_no_wheat = ale_dataset %>% filter(!grepl('.*Wheat*', ale_dataset$Style))
```









# Get ale data set
```{r}
ale_dataset = dataset %>% filter(grepl('.* Ale.*', dataset$Style))
ale_dataset = ale_dataset %>% filter(!grepl('.*IPA.*', ale_dataset$Style))
ale_dataset = ale_dataset %>% filter(!grepl('.* Pale.*', ale_dataset$Style))
ale_dataset = ale_dataset %>% filter(!grepl('.* Red.*', ale_dataset$Style))
ale_dataset$Style = as.factor(ale_dataset$Style)
```










### Is there a relationship between the number of beers of a given style and their ABV and/or IBU
# Create a dataframe that contains the count for each beer style
```{r}
tally_df = dataset %>% group_by(Style) %>% tally()
tally_df = merge(dataset, tally_df, by = 'Style', all.x = TRUE, all.y = FALSE)
```

# Split the data into training and test sets
```{r}
splitpercent = .70
trainIndices = sample(1:dim(tally_df)[1], round(splitpercent * dim(tally_df)[1]))
lm_train = tally_df[trainIndices,]
lm_test = tally_df[-trainIndices,]
```


# Create a linear model that predicts the style count using ABV and IBU
```{r}
linear_model = lm(n ~ ABV + IBU , data = lm_train)
summary(linear_model)
```


# Test the linear model
```{r}
linear_results = predict(linear_model, subset(lm_test, select = c(8,9)), type = 'response')
lm_test$Predicted_n = linear_results
lm_test$Model_resid = lm_test$n - lm_test$Predicted_n

lm_plot <- plot_ly(lm_test, x = ~IBU, y = ~ABV, z = ~n, color = ~Style) 
lm_plot
```










################# FAILURES BELOW ######################










# Create a 2D Scatter plot of ABV vs IBU colored by model Correctness with a 50% Probability contour line added
```{r}
x <- seq(min(class_df$IBU), max(class_df$IBU), length.out=119)
y <- seq(min(class_df$ABV), max(class_df$ABV), length.out=13)
pr <-data.frame(x = rep(x, length(y)), y = rep(y, each = length(x)), z = as.vector(class_df$AleProb))


class_df %>% ggplot(aes(x = class_df$IBU, y = class_df$ABV, color = class_df$Correct)) + geom_point(position = 'jitter') + ggtitle('Model Decision Boundary') + scale_color_manual(values = c('red', 'blue')) + geom_contour(data = pr, aes(x = x, y = y, z = z), breaks = c(0, .5))


```













# Create a plot that includes a decision boundary
```{r}
class_df$Correct_Numeric = ifelse(class_df$Correct == TRUE, 1, 0)
class_df$Truth_Numeric = ifelse(class_df$Truth == 'Ale', 1, 0)
class_df$AleProb = ifelse(class_df$Classification == 'Ale', class_df$Probability, 1 - class_df$Probability)

graph_resolution = 0.005
axis_x = seq(min(ipa_ale_dataset$ABV), max(ipa_ale_dataset$ABV), by = graph_resolution)
axis_y = seq(min(ipa_ale_dataset$IBU), max(ipa_ale_dataset$IBU), by = graph_resolution*1800)

contour(x= axis_x, y = axis_y, z = as.matrix(class_df), levels = 0.5, col = 'grey', lwd = 2)




model_plot <- plot_ly(class_df, x = ~ABV, y = ~IBU, z = ~AleProb, color = ~Truth, colors = 'Set1')
model_plot <- model_plot %>% add_markers()
model_plot <- model_plot %>% layout(title = 'Beer Style Probability', scene = list(xaxis = list(title = 'ABV'),
                                  yaxis = list(title = 'IBU'),
                                  zaxis = list(title = 'Probability of Being an Ale')))

model_plot  


```


# Create a plot that includes a decision boundary
```{r}
class_df$Correct_Numeric = ifelse(class_df$Correct == TRUE, 1, 0)
class_df$Truth_Numeric = ifelse(class_df$Truth == 'Ale', 1, 0)
ale_df = class_df[class_df$Truth == 'Ale',]
ipa_df = class_df[class_df$Truth == 'IPA',]

ale_model = lm(data = ale_df, formula = Correct_Numeric ~ ABV + IBU)
ipa_model = lm(data = ipa_df, formula = Correct_Numeric ~ ABV + IBU)
ale_vals = predict(ale_model, newdata = ale_df)
ipa_vals = predict(ipa_model, newdata = ipa_df)
ale_vec = c(1)
ipa_vec = c(0)
ale_model_df = as.data.frame(cbind(ale_vals, ale_vec))
ipa_model_df = as.data.frame(cbind(ipa_vals, ipa_vec))

model_plot <- plot_ly(class_df, x = ~ABV, y = ~IBU, z = ~Truth_Numeric, color = ~Correct, colors = 'Set1')
model_plot <- model_plot %>% add_markers()
model_plot <- model_plot %>% layout(title = 'Distribution of ABV and IBU By Style', scene = list(xaxis = list(title = 'ABV'),
                                  yaxis = list(title = 'IBU'),
                                  zaxis = list(title = 'True Style')))
model_plot <- model_plot %>% plot_ly(data = class_df,z = as.matrix(class_df$Probability))
model_plot <- model_plot %>% add_surface()
model_plot  
  
model_plot <- model_plot %>% add_lines(x = ~ABV, y = ~IBU, z = ~as.matrix(ale_model_df$ale_vals, color = 'black', width = 3))

```






graph_resolution = .01
axis_x = seq(min(ipa_ale_dataset$ABV), max(ipa_ale_dataset$ABV), by = graph_resolution)
axis_y = seq(min(ipa_ale_dataset$IBU), max(ipa_ale_dataset$IBU), by = graph_resolution)

class_surface = expand.grid(ABV = axis_x, IBU = axis_y, KEEP.OUT.ATTRS = F)
class_surface$Style = predict.lm(model, newdata = class_surface)
class_surface <- acast(class_surface, ABV ~ IBU, value.var = "Style")


model_plot <- plot_ly(class_df, x = ~ABV, y = ~IBU, z = ~Truth_Numeric, color = ~Correct, colors = 'Set1')
model_plot <- model_plot %>% add_markers()
model_plot <- model_plot %>% layout(title = 'Distribution of ABV and IBU By Style', scene = list(xaxis = list(title = 'ABV'),
                                  yaxis = list(title = 'IBU'),
                                  zaxis = list(title = 'True Style')))
#model_plot <- add_trace(p = model_plot, z = class_surface, x = axis_x, y = axis_y, type = 'surface')



```{r}
### This creates a surface
graph_resolution = .01

axis_x = seq(min(ipa_ale_dataset$ABV), max(ipa_ale_dataset$ABV), by = graph_resolution)
axis_y = seq(min(ipa_ale_dataset$IBU), max(ipa_ale_dataset$IBU), by = graph_resolution)

class_surface = expand.grid(ABV = axis_x, IBU = axis_y, KEEP.OUT.ATTRS = F)
class_surface$Style = predict.lm(model, newdata = class_surface)
class_surface <- acast(class_surface, ABV ~ IBU, value.var = "Style")


model_plot <- plot_ly(class_df, x = ~ABV, y = ~IBU, z = ~Truth, color = ~Correct, colors = 'Set1')
model_plot <- model_plot %>% add_markers()
model_plot <- model_plot %>% layout(title = 'Distribution of ABV and IBU By Style', scene = list(xaxis = list(title = 'ABV'),
                                  yaxis = list(title = 'IBU'),
                                  zaxis = list(title = 'True Style')))
#model_plot <- add_trace(p = model_plot, z = class_surface, x = axis_x, y = axis_y, type = 'surface')
########
model_plot
```


abv = unique(class_df$ABV)
ibu = unique(class_df$IBU)



grid <- with(class_df, expand.grid(abv, ibu))
prob = attr(classifications, 'prob')
prob <- ifelse(classifications == '1', prob, 1 - prob)
prob_matrix = matrix(prob, nrow = length(abv), ncol = length(ibu))

contour(class_df$ABV, class_df$IBU, prob_matrix, levels = 0.5)


```{r}
classes.grid = knn.cv(class_df, grid, classifications, k = 5, prob = T)
prob.grid <- attr(classes.grid, 'prob')
prob.grid <- ifelse(classes.grid == 'IPA', prob.grid, 1 - prob.grid)

# Plot boundary
contour(x = 0:0.1, y = 0:140, z = matrix(class_df$Probability, nrow = length(class_df$Probability)), levels = 0.5, col = 'grey', drawlabels = F, lwd = 2)
points(class_df, col = class_df$Correct)



```

##### Visualize model performance by style
# Create a linear regression line for each style 
```{r}
ipa_df = class_df[class_df$Truth == 'IPA',]
ipa_df$Correct = ifelse(ipa_df$Correct == TRUE, 1, 0)

#ipa_df$Numeric = c(1)
ipa_reg = lm(formula = Correct ~ ABV + IBU, data = ipa_df)


ipa.abv = unique(ipa_df$ABV)
ipa.ibu = unique(ipa_df$IBU)
ipagrid <- with(ipa_df, expand.grid(ipa.abv, ipa.ibu))
ipa_d = setNames(data.frame(grid), c('ABV', 'IBU'))
ipa_values = predict(ipa_reg, newdata = ipa_d)
```

```{r}
#ipa_reg <- matrix(ipa_values)
                  #, nrow = length(unique(ipa_d$abv)), ncol = length(unique(ipa_d$ibu)))
ipa_matrix = matrix(ipa_values, nrow = length(unique(ipa_d$abv)), ncol = length(unique(ipa_d$ibu)))

# z = probability or Numeric
ipa_model_plot <- plot_ly(ipa_model, x = ~ABV, y = ~IBU, z = ~Numeric, color = ~Correct, colors = 'Set1')
ipa_model_plot <- ipa_model_plot %>% add_markers()
ipa_model_plot <- ipa_model_plot %>% layout(title = 'Model Performance on IPAs', scene = list(xaxis = list(title = 'ABV'),
                                  yaxis = list(title = 'IBU'),
                                  zaxis = list(title = 'Probability')))
ipa_model_plot <- add_trace(ipa_matrix, x = ~ABV, y = ~IBU, z = ~ipa_reg)
#ipa_model_plot <- ipa_model_plot %>% add_surface(x = ~ABV, y = ~IBU, z = ~ipa_reg)
ipa_model_plot

```

```{r}
ale_model = class_df[class_df$Truth == 'Ale',]

ale_model_plot <- plot_ly(ale_model, x = ~ABV, y = ~IBU, z = ~Probability, color = ~Correct, colors = 'Set1')
ale_model_plot <- ale_model_plot %>% add_markers()
ale_model_plot <- ale_model_plot %>% layout(title = 'Model Performance On Ales', scene = list(xaxis = list(title = 'ABV'),
                                  yaxis = list(title = 'IBU'),
                                  zaxis = list(title = 'Probability')))
ale_model_plot
```


### Create trendline by creating a surface
# fit model and plot the surface along with the model results
```{r}
m = lm(ABV ~ IBU + Numeric, data = class_df)

abv = unique(class_df$ABV)
ibu = unique(class_df$IBU)
numeric = as.numeric(unique(class_df$Numeric))

grid = with(class_df, expand.grid(abv, ibu, Numeric))
d <- setNames(data.frame(grid), c('ABV', 'IBU', 'Numeric'))
values = predict(m, newdata = d)

# form matrix and plot with model performance
m = matrix(values, nrow = length(unique(d$ABV)), ncol = length(unique(d$IBU)))
numeric_matrix = as.matrix(class_df[, 7])

model_plot <- plot_ly(class_df, x = ~ABV, y = ~IBU, z = ~numeric_matrix, color = ~Correct, colors = 'Set1')
model_plot <- model_plot %>% add_markers()
model_plot <- model_plot %>% layout(title = 'Distribution of ABV and IBU By Style', scene = list(xaxis = list(title = 'ABV'),
                                  yaxis = list(title = 'IBU'),
                                  zaxis = list(title = 'True Style')))
# Used Numeric for z instead of true style here
model_plot <- model_plot %>% add_surface(x = d$ABV, y = d$IBU, z = numeric_matrix, type = 'surface',
                                       opacity = 1, colors = c('#d1d1d1', '#000000'))
model_plot
```













































# Create a linear model playground
```{r}
linear_model = lm(ABV ~ IBU , data = lm_train)
summary(linear_model)
```




model_plot <- plot_ly(class_df, x = ~ABV, y = ~IBU, z = ~Truth, color = ~Correct, colors = 'Set1')
model_plot <- model_plot %>% add_markers()
model_plot <- model_plot %>% layout(title = 'Distribution of ABV and IBU By Style', scene = list(xaxis = list(title = 'ABV'),
                                  yaxis = list(title = 'IBU'),
                                  zaxis = list(title = 'True Style')))
model_plot
```




fitted.results = predict(logistic_regression_model, newdata = subset(ipa_ale_test, select = c(7, 8)), type = 'response')
fitted.results = ifelse(fitted.results > 0.5, 'IPA', 'Ale')

misclass_error = mean(fitted.results != ipa_ale_test$Style)
print(paste('Accuracy is ', 1 - misclass_error))

